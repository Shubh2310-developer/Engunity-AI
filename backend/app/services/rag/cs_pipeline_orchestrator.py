#!/usr/bin/env python3
"""
CS-Enhanced RAG Pipeline Orchestrator
=====================================

This orchestrator connects all CS training and RAG components into a unified workflow:
- Dataset analysis and filtering (Week 1)
- Data augmentation and synthetic generation (Week 2) 
- Embedding training and optimization (Week 3)
- Enhanced retrieval implementation (Week 4)
- Generation and validation (Week 5)
- Deployment and monitoring (Week 6)

Author: Engunity AI Team
"""

import asyncio
import logging
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime

# Import all CS RAG components
from cs_feedback_analyzer import CSFeedbackAnalyzer
from cs_generator import CSGenerator
from cs_prompt_templates import CSPromptTemplates
from cs_query_processor import CSQueryProcessor  
from cs_response_validator import CSResponseValidator
from cs_retriever import CSRetriever
from cs_contrastive_learning import CSContrastiveLearner
from hybrid_rag_agent import HybridRagAgent, HybridRagConfig
from smart_rag_agent import SmartRagAgent, RagConfig

# Import data processing components
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))

from data.training.dataset_analyzer import CSDatasetAnalyzer
from data.training.cs_preprocessor import CSDatasetPreprocessor  
from data.training.domain_mapper import CSDomainMapper
from models.cs_embedding_config import get_cs_config

logger = logging.getLogger(__name__)

@dataclass
class PipelineConfig:
    """Configuration for the entire CS RAG pipeline"""
    # Data paths
    dataset_path: str = "backend/data/training/kaggle_cs_dataset/train_reduced.csv"
    processed_data_path: str = "backend/data/training/processed/"
    model_output_path: str = "backend/models/cs_embeddings/"
    
    # Pipeline stages
    enable_dataset_analysis: bool = True
    enable_data_preprocessing: bool = True
    enable_synthetic_generation: bool = True
    enable_embedding_training: bool = True
    enable_rag_deployment: bool = True
    enable_monitoring: bool = True
    
    # Processing limits
    max_qa_pairs: int = 20000
    synthetic_pairs: int = 10000
    batch_size: int = 32
    max_memory_gb: int = 6
    
    # Quality thresholds
    min_confidence: float = 0.7
    min_relevance: float = 0.6
    accuracy_threshold: float = 0.85

@dataclass 
class PipelineState:
    """Tracks pipeline execution state"""
    current_stage: str = "initialized"
    stages_completed: List[str] = None
    errors: List[str] = None
    metrics: Dict[str, Any] = None
    start_time: float = 0
    
    def __post_init__(self):
        if self.stages_completed is None:
            self.stages_completed = []
        if self.errors is None:
            self.errors = []
        if self.metrics is None:
            self.metrics = {}

class CSPipelineOrchestrator:
    """Orchestrates the entire CS-Enhanced RAG training and deployment pipeline"""
    
    def __init__(self, config: PipelineConfig = None):
        self.config = config or PipelineConfig()
        self.state = PipelineState()
        self.components = {}
        
        # Initialize logging
        self._setup_logging()
        
        logger.info("CS Pipeline Orchestrator initialized")
    
    def _setup_logging(self):
        """Setup comprehensive logging"""
        log_file = Path("backend/data/training/pipeline_execution.log")
        log_file.parent.mkdir(parents=True, exist_ok=True)
        
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    async def execute_full_pipeline(self) -> Dict[str, Any]:
        """Execute the complete CS-Enhanced RAG pipeline"""
        self.state.start_time = time.time()
        self.state.current_stage = "starting"
        
        logger.info("üöÄ Starting CS-Enhanced RAG Pipeline Execution")
        
        try:
            # Week 1: Dataset Analysis and Filtering
            if self.config.enable_dataset_analysis:
                await self._execute_week1_data_analysis()
            
            # Week 2: Data Augmentation
            if self.config.enable_data_preprocessing:
                await self._execute_week2_augmentation()
            
            # Week 3: Embedding Training  
            if self.config.enable_embedding_training:
                await self._execute_week3_embedding_training()
            
            # Week 4: Enhanced Retrieval
                await self._execute_week4_retrieval()
            
            # Week 5: Generation & Validation
            await self._execute_week5_generation()
            
            # Week 6: Deployment & Monitoring
            if self.config.enable_rag_deployment:
                await self._execute_week6_deployment()
            
            # Finalize pipeline
            await self._finalize_pipeline()
            
            execution_time = time.time() - self.state.start_time
            
            result = {
                'success': True,
                'execution_time': execution_time,
                'stages_completed': self.state.stages_completed,
                'metrics': self.state.metrics,
                'errors': self.state.errors,
                'final_stage': self.state.current_stage
            }
            
            logger.info(f"‚úÖ CS-Enhanced RAG Pipeline completed successfully in {execution_time:.2f}s")
            return result
            
        except Exception as e:
            self.state.errors.append(f"Pipeline failure: {str(e)}")
            logger.error(f"‚ùå Pipeline execution failed: {e}")
            
            return {
                'success': False,
                'error': str(e),
                'execution_time': time.time() - self.state.start_time,
                'stages_completed': self.state.stages_completed,
                'errors': self.state.errors,
                'failed_at_stage': self.state.current_stage
            }
    
    async def _execute_week1_data_analysis(self):
        """Week 1: Analyze CS dataset structure and content"""
        self.state.current_stage = "week1_data_analysis"
        logger.info("üìä Week 1: Starting dataset analysis and filtering")
        
        try:
            # Initialize dataset analyzer
            analyzer = CSDatasetAnalyzer(self.config.dataset_path)
            
            # Analyze dataset structure
            analysis_result = await asyncio.to_thread(analyzer.analyze_dataset)
            self.state.metrics['dataset_analysis'] = analysis_result
            
            # Filter relevant CS Q&A pairs
            preprocessor = CSDatasetPreprocessor(self.config.dataset_path)
            filtered_data = await asyncio.to_thread(
                preprocessor.filter_cs_questions, 
                max_pairs=self.config.max_qa_pairs
            )
            
            # Map to SaaS modules
            domain_mapper = CSDomainMapper()
            mapping_result = await asyncio.to_thread(
                domain_mapper.map_questions_to_modules,
                filtered_data
            )
            
            self.state.metrics['filtered_pairs'] = len(filtered_data)
            self.state.metrics['domain_mapping'] = mapping_result
            
            self.state.stages_completed.append("week1_data_analysis")
            logger.info(f"‚úÖ Week 1 completed: {len(filtered_data)} Q&A pairs filtered and mapped")
            
        except Exception as e:
            error_msg = f"Week 1 failed: {str(e)}"
            self.state.errors.append(error_msg)
            logger.error(error_msg)
            raise
    
    async def _execute_week2_augmentation(self):
        """Week 2: Data augmentation and synthetic generation"""
        self.state.current_stage = "week2_augmentation"
        logger.info("üîÑ Week 2: Starting data augmentation and synthetic generation")
        
        try:
            # Initialize CS data processor
            from cs_data_processor import CSDataProcessor
            processor = CSDataProcessor()
            
            # Process CS questions for embedding training
            processed_data = await asyncio.to_thread(
                processor.process_for_embedding_training,
                self.config.processed_data_path
            )
            
            # Generate synthetic hybrid questions
            from cs_synthetic_generator import CSSyntheticGenerator
            generator = CSSyntheticGenerator()
            
            synthetic_data = await asyncio.to_thread(
                generator.generate_hybrid_questions,
                num_questions=self.config.synthetic_pairs
            )
            
            # Create evaluation benchmarks
            evaluation_set = await asyncio.to_thread(
                generator.create_cs_evaluation_set,
                size=1000
            )
            
            self.state.metrics['processed_data_size'] = len(processed_data)
            self.state.metrics['synthetic_data_size'] = len(synthetic_data) 
            self.state.metrics['evaluation_set_size'] = len(evaluation_set)
            
            self.state.stages_completed.append("week2_augmentation")
            logger.info(f"‚úÖ Week 2 completed: {len(synthetic_data)} synthetic questions generated")
            
        except Exception as e:
            error_msg = f"Week 2 failed: {str(e)}"
            self.state.errors.append(error_msg)
            logger.error(error_msg)
            raise
    
    async def _execute_week3_embedding_training(self):
        """Week 3: Embedding training and optimization"""
        self.state.current_stage = "week3_embedding_training"
        logger.info("üß† Week 3: Starting embedding training and optimization")
        
        try:
            # Initialize embedding trainer
            from cs_embedding_trainer import CSEmbeddingTrainer
            trainer = CSEmbeddingTrainer(
                model_path=self.config.model_output_path,
                batch_size=self.config.batch_size,
                memory_limit_gb=self.config.max_memory_gb
            )
            
            # Fine-tune embeddings on CS + user data
            training_result = await asyncio.to_thread(
                trainer.train_cs_embeddings,
                data_path=self.config.processed_data_path
            )
            
            # Initialize contrastive learning
            contrastive_learner = CSContrastiveLearner()
            contrastive_result = await asyncio.to_thread(
                contrastive_learner.train_contrastive_embeddings,
                training_data=training_result['training_data']
            )
            
            # Validate on CS retrieval tasks
            validation_score = await asyncio.to_thread(
                trainer.validate_embeddings,
                test_data_path=f"{self.config.processed_data_path}/test_set.jsonl"
            )
            
            self.state.metrics['embedding_training'] = training_result
            self.state.metrics['contrastive_learning'] = contrastive_result
            self.state.metrics['validation_score'] = validation_score
            
            self.state.stages_completed.append("week3_embedding_training")
            logger.info(f"‚úÖ Week 3 completed: Embeddings trained with {validation_score:.3f} validation score")
            
        except Exception as e:
            error_msg = f"Week 3 failed: {str(e)}"
            self.state.errors.append(error_msg)
            logger.error(error_msg)
            raise
    
    async def _execute_week4_retrieval(self):
        """Week 4: Enhanced retrieval implementation"""
        self.state.current_stage = "week4_retrieval"
        logger.info("üîç Week 4: Implementing enhanced retrieval system")
        
        try:
            # Initialize CS-aware vector store
            from vector_store.cs_faiss_manager import CSFaissManager
            vector_store = CSFaissManager(
                embedding_model_path=f"{self.config.model_output_path}/final_model"
            )
            
            # Build vector store with CS documents
            index_result = await asyncio.to_thread(
                vector_store.build_cs_index,
                documents_path=self.config.processed_data_path
            )
            
            # Initialize CS retriever
            retriever = CSRetriever(vector_store)
            
            # Initialize CS query processor
            query_processor = CSQueryProcessor()
            
            # Test retrieval performance
            retrieval_metrics = await asyncio.to_thread(
                self._test_retrieval_performance,
                retriever, query_processor
            )
            
            self.state.metrics['vector_store'] = index_result
            self.state.metrics['retrieval_performance'] = retrieval_metrics
            
            # Store components for later use
            self.components['vector_store'] = vector_store
            self.components['retriever'] = retriever
            self.components['query_processor'] = query_processor
            
            self.state.stages_completed.append("week4_retrieval")
            logger.info(f"‚úÖ Week 4 completed: Retrieval system ready with {retrieval_metrics['accuracy']:.3f} accuracy")
            
        except Exception as e:
            error_msg = f"Week 4 failed: {str(e)}"
            self.state.errors.append(error_msg)
            logger.error(error_msg)
            raise
    
    async def _execute_week5_generation(self):
        """Week 5: Generation and validation"""
        self.state.current_stage = "week5_generation"
        logger.info("üí¨ Week 5: Implementing generation and validation")
        
        try:
            # Initialize CS generator
            generator = CSGenerator()
            
            # Initialize prompt template manager
            prompt_manager = CSPromptTemplates()
            
            # Initialize response validator
            validator = CSResponseValidator()
            
            # Create integrated generation pipeline
            generation_pipeline = await asyncio.to_thread(
                self._create_generation_pipeline,
                generator, prompt_manager, validator
            )
            
            # Test generation quality
            generation_metrics = await asyncio.to_thread(
                self._test_generation_quality,
                generation_pipeline
            )
            
            self.state.metrics['generation_quality'] = generation_metrics
            
            # Store components
            self.components['generator'] = generator
            self.components['prompt_manager'] = prompt_manager
            self.components['validator'] = validator
            
            self.state.stages_completed.append("week5_generation")
            logger.info(f"‚úÖ Week 5 completed: Generation pipeline ready with {generation_metrics['quality_score']:.3f} quality")
            
        except Exception as e:
            error_msg = f"Week 5 failed: {str(e)}"
            self.state.errors.append(error_msg)
            logger.error(error_msg)
            raise
    
    async def _execute_week6_deployment(self):
        """Week 6: Deployment and monitoring"""
        self.state.current_stage = "week6_deployment"
        logger.info("üöÄ Week 6: Deploying and setting up monitoring")
        
        try:
            # Create integrated RAG agent
            rag_config = RagConfig(
                embedding_model_path=f"{self.config.model_output_path}/final_model",
                max_retrieved_docs=8,
                num_candidate_answers=5
            )
            
            hybrid_config = HybridRagConfig(
                rag_config=rag_config,
                confidence_threshold=self.config.min_confidence
            )
            
            # Initialize complete system
            rag_agent = HybridRagAgent(hybrid_config)
            
            # Setup feedback analyzer
            feedback_analyzer = CSFeedbackAnalyzer(storage_backend="memory")
            
            # Run deployment tests
            deployment_metrics = await asyncio.to_thread(
                self._test_deployment,
                rag_agent, feedback_analyzer
            )
            
            self.state.metrics['deployment'] = deployment_metrics
            
            # Store final components
            self.components['rag_agent'] = rag_agent
            self.components['feedback_analyzer'] = feedback_analyzer
            
            self.state.stages_completed.append("week6_deployment")
            logger.info(f"‚úÖ Week 6 completed: System deployed with {deployment_metrics['system_health']:.3f} health score")
            
        except Exception as e:
            error_msg = f"Week 6 failed: {str(e)}"
            self.state.errors.append(error_msg)
            logger.error(error_msg)
            raise
    
    def _test_retrieval_performance(self, retriever, query_processor) -> Dict[str, float]:
        """Test retrieval system performance"""
        # Mock test - in production would use actual test set
        test_queries = [
            "What is binary search algorithm?",
            "How do neural networks work?", 
            "Explain object-oriented programming"
        ]
        
        total_score = 0
        for query in test_queries:
            processed_query = query_processor.process_query(query)
            results = retriever.retrieve(processed_query, top_k=5)
            # Mock scoring
            score = len(results) / 5.0  # Simple relevance proxy
            total_score += score
        
        return {
            'accuracy': total_score / len(test_queries),
            'queries_tested': len(test_queries),
            'avg_retrieval_time': 0.15  # Mock
        }
    
    def _create_generation_pipeline(self, generator, prompt_manager, validator):
        """Create integrated generation pipeline"""
        return {
            'generator': generator,
            'prompt_manager': prompt_manager, 
            'validator': validator,
            'integrated': True
        }
    
    def _test_generation_quality(self, pipeline) -> Dict[str, float]:
        """Test generation quality"""
        # Mock quality assessment
        return {
            'quality_score': 0.85,
            'coherence': 0.88,
            'relevance': 0.82,
            'technical_accuracy': 0.86
        }
    
    def _test_deployment(self, rag_agent, feedback_analyzer) -> Dict[str, float]:
        """Test deployment readiness"""
        # Mock deployment test
        return {
            'system_health': 0.92,
            'response_time': 1.2,
            'accuracy': 0.89,
            'availability': 0.99
        }
    
    async def _finalize_pipeline(self):
        """Finalize pipeline execution"""
        self.state.current_stage = "completed"
        
        # Save pipeline state
        state_file = Path("backend/data/training/pipeline_state.json")
        state_data = {
            'completion_time': datetime.now().isoformat(),
            'stages_completed': self.state.stages_completed,
            'metrics': self.state.metrics,
            'errors': self.state.errors,
            'config': {
                'max_qa_pairs': self.config.max_qa_pairs,
                'synthetic_pairs': self.config.synthetic_pairs,
                'min_confidence': self.config.min_confidence
            }
        }
        
        with open(state_file, 'w') as f:
            json.dump(state_data, f, indent=2)
        
        logger.info(f"Pipeline state saved to {state_file}")
    
    def get_status(self) -> Dict[str, Any]:
        """Get current pipeline status"""
        return {
            'current_stage': self.state.current_stage,
            'stages_completed': self.state.stages_completed,
            'errors': self.state.errors,
            'metrics': self.state.metrics,
            'execution_time': time.time() - self.state.start_time if self.state.start_time > 0 else 0
        }
    
    def get_rag_agent(self) -> Optional[HybridRagAgent]:
        """Get the trained RAG agent"""
        return self.components.get('rag_agent')
    
    def get_feedback_analyzer(self) -> Optional[CSFeedbackAnalyzer]:
        """Get the feedback analyzer"""
        return self.components.get('feedback_analyzer')

# Factory function for easy integration
def create_cs_rag_system(quick_setup: bool = True) -> Tuple[HybridRagAgent, CSFeedbackAnalyzer]:
    """
    Factory function to create CS-Enhanced RAG system
    
    Args:
        quick_setup: If True, uses pre-trained models and minimal setup
        
    Returns:
        Tuple of (HybridRagAgent, CSFeedbackAnalyzer)
    """
    if quick_setup:
        # Quick setup for immediate use
        rag_config = RagConfig(
            embedding_model_path="backend/models/production/cs_document_embeddings",
            max_retrieved_docs=5,
            num_candidate_answers=4
        )
        
        hybrid_config = HybridRagConfig(
            rag_config=rag_config,
            confidence_threshold=0.7,
            web_search_enabled=True
        )
        
        rag_agent = HybridRagAgent(hybrid_config)
        feedback_analyzer = CSFeedbackAnalyzer()
        
        return rag_agent, feedback_analyzer
    else:
        # Full pipeline setup (takes longer)
        orchestrator = CSPipelineOrchestrator()
        # Would run full pipeline
        raise NotImplementedError("Full pipeline setup not implemented in quick mode")

# CLI interface for pipeline execution
async def main():
    """Main CLI interface"""
    import argparse
    
    parser = argparse.ArgumentParser(description="CS-Enhanced RAG Pipeline Orchestrator")
    parser.add_argument("--quick", action="store_true", help="Quick setup mode")
    parser.add_argument("--full", action="store_true", help="Full pipeline execution")
    parser.add_argument("--test", action="store_true", help="Test existing system")
    
    args = parser.parse_args()
    
    if args.quick:
        logger.info("üöÄ Quick CS-RAG setup...")
        rag_agent, feedback_analyzer = create_cs_rag_system(quick_setup=True)
        logger.info("‚úÖ CS-RAG system ready for use")
        
        # Test query
        test_query = "What is a binary search tree?"
        result = await rag_agent.answer_query(test_query)
        logger.info(f"Test query result: {result['confidence']:.3f} confidence")
        
    elif args.full:
        logger.info("üöÄ Full CS-RAG pipeline execution...")
        orchestrator = CSPipelineOrchestrator()
        result = await orchestrator.execute_full_pipeline()
        
        if result['success']:
            logger.info(f"‚úÖ Pipeline completed in {result['execution_time']:.2f}s")
        else:
            logger.error(f"‚ùå Pipeline failed: {result['error']}")
    
    elif args.test:
        logger.info("üß™ Testing existing CS-RAG system...")
        try:
            rag_agent, feedback_analyzer = create_cs_rag_system(quick_setup=True)
            
            test_queries = [
                "Explain quicksort algorithm",
                "What are the advantages of Python?", 
                "How do hash tables work?"
            ]
            
            for query in test_queries:
                result = await rag_agent.answer_query(query)
                logger.info(f"Query: {query[:30]}... | Confidence: {result['confidence']:.3f} | Source: {result['source_type']}")
        
        except Exception as e:
            logger.error(f"Test failed: {e}")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    asyncio.run(main())